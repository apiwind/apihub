# Mixtral 8x7B Instruct

A pretrained generative Sparse Mixture of Experts, by Mistral AI, for chat and instruction use. Incorporates 8 experts (feed-forward networks) for a total of 47 billion parameters.
Instruct model fine-tuned by Mistral. #moe

Nombre del enlace de la fuente: [https://openrouter.ai/models/mistralai/mixtral-8x7b-instruct](https://openrouter.ai/models/mistralai/mixtral-8x7b-instruct)

## Documentaci√≥n de la API

[Mixtral 8x7B Instruct API Docs](../apis/es/Mixtral_8x7B_Instruct.md)

## Precio de la API

| Router Abierto | APIhub |
|:---|:---|
| input: $0.24 output: $0.24 | input: $0.24*60% output: $0.24*60% |
