{"openapi":"Mixtral 8x7B Instruct.json","apidocs":"","openapi_json":null,"info":{"us":{"name":"Mixtral 8x7B Instruct","description":"A pretrained generative Sparse Mixture of Experts, by Mistral AI, for chat and instruction use. Incorporates 8 experts (feed-forward networks) for a total of 47 billion parameters.\nInstruct model fine-tuned by Mistral. #moe","info":{"about":"","case":null},"sourcelink":"https://openrouter.ai/models/mistralai/mixtral-8x7b-instruct","price":{"input":"$0.24","output":"$0.24"},"category":{"LLM":[]}}}}